{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count-Min Sketch\n",
    "---\n",
    "\n",
    "The Count-Min (CM) sketch is a probabilistic data structure that provides\n",
    "a lossy form of compression for large count/frequency datasets.\n",
    "It is typically used for streaming data. At the heart of the CM sketch\n",
    "is hashing. The CM sketch uses a set of hash functions with corresponding,\n",
    "constant size, hash tables. These hash functions are independent from one\n",
    "another. Since the hash functions are independent, each distributes\n",
    "data differently within its hash table. This independent hashing redundancy allows\n",
    "CM sketches to achieve a high degree of lossy compression while still \n",
    "producing quality estimates of the original data.\n",
    "\n",
    "### Internals\n",
    "---\n",
    "The core data storage structure within a CM sketch is a $w$ * $d$ table, $\\text{count}$. $w$ is given by $w = \\left\\lceil\\frac{e}{\\epsilon}\\right\\rceil$ and d is given by $d = \\ln\\left(\\frac{1}{\\delta}\\right)$. $\\epsilon$ is the additive error factor that a result will be within with probability $1-\\delta$.\n",
    "\n",
    "<img src=\"./img/cm_internal_table.png\" width=\"400\" />\n",
    "\n",
    "Each row in the table is used as the hash table for one of the $1..d$ hash functions. When we add an event to the sketch, its count is added to each row.\n",
    "\n",
    "<img src=\"./img/cm_adding_event.png\" width=\"400\" />\n",
    "\n",
    "### Operations\n",
    "---\n",
    "#### Point Query $Q(i)$\n",
    "A point query is the estimation of $a_i$ from the original data.\n",
    "\n",
    "<img src=\"./img/cm_point_q.png\" width=\"400\" />\n",
    "$$Q(i) = \\min_j\\text{count}[j, h_j(i)]$$\n",
    "\n",
    "#### Range Query $Q(l, r)$\n",
    "A range query from $l..r$ is the estimation of the sum over that range.\n",
    "$$Q(l,r) = \\sum_{i=l}^r a_i$$\n",
    "To accuratly calculate a range query, $log(n)$ sketches must be kept; one for each set of dyadic ranges spanning $1..n$.\n",
    "\n",
    "#### Inner Product $Q(\\boldsymbol{a}, \\boldsymbol{b})$\n",
    "The inner product between two arrays can be estimated using a sketch for each array and taking the minimum row-wise inner product.\n",
    "$$Q(\\boldsymbol{a}, \\boldsymbol{b}) = \\min_j\\sum_{k=1}^n\\text{count}_a[j, k]*\\text{count}_b[j, k]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # visualizations\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import sys\n",
    "import mmh3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naively count frequencies\n",
    "\n",
    "class dictionary():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dictionary = {}\n",
    "        self.nbytes = sys.getsizeof(self)\n",
    "    \n",
    "    def getsize(self):\n",
    "        print(\"Dictionary is Size: {} Bytes\\n\".format(self.nbytes))\n",
    "        \n",
    "    def add(self,token):\n",
    "        if token in self.dictionary:\n",
    "            self.dictionary[token] += 1\n",
    "        else:\n",
    "            self.dictionary[token] = 1\n",
    "        self.nbytes = sys.getsizeof(self.dictionary)\n",
    "        \n",
    "    def timed_update(self,tokenlist):\n",
    "        startsize = self.nbytes\n",
    "        start = time.time()\n",
    "        for token in tokenlist:\n",
    "            self.add(token)\n",
    "        end = time.time() - start\n",
    "        dsize = self.nbytes - startsize\n",
    "        print(\"Time Elapsed: {} Seconds \\n\".format(end))\n",
    "        print(\"Change In Memory: {} Bytes\\n\".format(dsize))\n",
    "    \n",
    "    def estimate(self,token):\n",
    "        try:\n",
    "            return self.dictionary[token]\n",
    "        except:\n",
    "            print(\"Error: Token Not Found \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CountMinSketch():\n",
    "    \n",
    "    def __init__(self,indexes=2**5,hashfuncs=2**5):\n",
    "        self.N = indexes\n",
    "        self.M = hashfuncs\n",
    "\n",
    "        self.seeds = np.arange(hashfuncs).tolist()\n",
    "        self.table = np.zeros((self.M,self.N))\n",
    "        self.hashes = [self._genhash(seed) for seed in self.seeds]\n",
    "        self.nbytes = sys.getsizeof(self.table) + sys.getsizeof(self.hashes)\n",
    "        \n",
    "    def _genhash(self,prime):\n",
    "        def hash_fn(val):\n",
    "            index = mmh3.hash(val,seed=prime)\n",
    "            return index%self.M\n",
    "        return hash_fn\n",
    "\n",
    "    def getsize(self):\n",
    "        print(\"Sketch is Size: {} Bytes\\n\".format(self.nbytes))\n",
    "        \n",
    "    def add(self, val):      \n",
    "        for ix in range(0, self.N):\n",
    "            h = self.hashes[ix](val)\n",
    "            self.table[ix][h] += 1\n",
    "\n",
    "            \n",
    "    def timed_update(self,valuelist):\n",
    "        start = time.time()\n",
    "        for value in valuelist:\n",
    "            self.add(value)\n",
    "        end = time.time() - start\n",
    "        dsize = sys.getsizeof(self.table) + sys.getsizeof(self.hashes)\n",
    "        print(\"Time Elapsed: {} Seconds \\n\".format(end))\n",
    "        print(\"Memory Useage: {} Bytes\\n\".format(dsize))\n",
    "                              \n",
    "                              \n",
    "       \n",
    "    def count(self,val):\n",
    "        # Helper Function\n",
    "        vals = []\n",
    "        for ix in range(0, N):\n",
    "            h = self.hashes[ix](val)\n",
    "            vals.append(self.table[h][ix])\n",
    "        return vals\n",
    "            \n",
    "    def estimate(self, value):\n",
    "   \n",
    "        results = []\n",
    "        for ix in range(0, N):\n",
    "            h = self.hashes[ix](value)\n",
    "            c = self.table[h][ix]\n",
    "            results.append(c)\n",
    "        return min(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class changeDetection():\n",
    "    def __init__(self,sketchset,w):\n",
    "        self.sketchset = sketchset\n",
    "        self.w = w\n",
    "        self.MA = None\n",
    "        \n",
    "    def update(self,sketch):\n",
    "        self.sketchset.append(sketch)\n",
    "        if len(self.sketchet >self.w):\n",
    "            self.sketchset.pop(0)\n",
    "        self.calcmovingAv()\n",
    "            \n",
    "    def calcmovingAv(self):\n",
    "        tableav = 0\n",
    "        for i,sketch in enumerate(self.sketchset):\n",
    "            tableav += sketch.table\n",
    "        tableav /= len(self.sketchset)\n",
    "        self.MA = tableav\n",
    "        \n",
    "    def indmovingAv(self,val):\n",
    "        # Helper Function\n",
    "        mavals = []\n",
    "        for ix in range(0, N):\n",
    "            h = self.sketchset[-1].hashes[ix](val)\n",
    "            mavals.append(self.MA[h][ix])\n",
    "        return mavals\n",
    "    \n",
    "    def bucketDist(self,value,idx):\n",
    "        # Helper Function\n",
    "        sketch = self.sketchset[idx]\n",
    "        K = np.sum(sketch.table > 0)\n",
    "        counts = sketch.count(vals)\n",
    "        vals = (counts - self.indmovingAv(value))\n",
    "        vals = [value/(1 - 1/K) for value in vals]\n",
    "        v_a  = np.median(vals)\n",
    "        return counts,v_a\n",
    "    \n",
    "    def isAttack(self,value,beta):\n",
    "        # given a set of values, compute their respective counts and determine the\n",
    "        # \"Change\" in the count frequency relative to their respective bins to dermine \n",
    "        # an anomoly\n",
    "        \n",
    "        # If the ID post count exceeds the criteria from the previous sketch\n",
    "        # then it qualifies as an attack\n",
    "        counts,variance = self.bucketDist(value,-1)\n",
    "        mean = self.MA\n",
    "        crit = mean + beta*variance\n",
    "        for count in counts:\n",
    "            if count > crit:\n",
    "                print(\"Found Anomoly: {},{}\".format(count,crit))\n",
    "                return True\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassification():\n",
    "    def __init__(self,A,B,update=False):\n",
    "        # Arguments are either:\n",
    "            #update = True : two respective lists of words from different datasets\n",
    "            \n",
    "            #update = False: Two previously instatiated instances of CountMinSketch()\n",
    "        self.streamA = CountMinSketch()\n",
    "        self.streamB = CountMinSketch()\n",
    "        if update:\n",
    "            self.streamB.timed_update(B)\n",
    "            self.streamA.timed_update(A)\n",
    "        else:\n",
    "            self.streamA = A\n",
    "            self.streamB = B\n",
    "      \n",
    "        \n",
    "        \n",
    "    def _dotProduct(self,tableA,tableB):\n",
    "        return np.min(tableA@tableB.T)\n",
    "        \n",
    "        \n",
    "    def classify(self,subsketch):\n",
    "        x = self._dotProduct(subsketch.table,self.streamA.table)\n",
    "        y = self._dotProduct(subsketch.table,self.streamB.table)\n",
    "        print(x,y)\n",
    "        print(x-y)\n",
    "        if x > y:\n",
    "            print(\"Words Originated from A\")\n",
    "        else:\n",
    "            print(\"Words Originated from B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruitfly = np.load(\"fruitfly.npy\")\n",
    "human = np.load(\"human1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 1.96034836769104 Seconds \n",
      "\n",
      "Change In Memory: 83886120 Bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genomedict = dictionary()\n",
    "genomedict.timed_update(human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "countsize = len(fruitfly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156246"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fruitfly)\n",
    "human = human[:len(fruitfly)]\n",
    "len(human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 4.866109132766724 Seconds \n",
      "\n",
      "Memory Useage: 8648 Bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genomesketch = CountMinSketch()\n",
    "genomesketch.timed_update(human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 4.850249767303467 Seconds \n",
      "\n",
      "Memory Useage: 8648 Bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fruitflysketch = CountMinSketch()\n",
    "fruitflysketch.timed_update(fruitfly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.sum(genomesketch.table) - np.sum(fruitflysketch.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 2.4383835792541504 Seconds \n",
      "\n",
      "Memory Useage: 8648 Bytes\n",
      "\n",
      "Time Elapsed: 2.404276132583618 Seconds \n",
      "\n",
      "Memory Useage: 8648 Bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subhuman = human[::2]\n",
    "subfly = fruitfly[::2]\n",
    "SH_sketch = CountMinSketch()\n",
    "SH_sketch.timed_update(subhuman)\n",
    "FF_sketch = CountMinSketch()\n",
    "FF_sketch.timed_update(subfly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fly_or_human = BinaryClassification(genomesketch,fruitflysketch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381353392.0 381370583.0\n",
      "-17191.0\n",
      "Words Originated from B\n"
     ]
    }
   ],
   "source": [
    "fly_or_human.classify(SH_sketch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381374195.0 381374906.0\n",
      "-711.0\n",
      "Words Originated from B\n"
     ]
    }
   ],
   "source": [
    "fly_or_human.classify(FF_sketch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
